<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Коан 6 Модели счетных данных | Розеттский камень</title>
  <meta name="description" content="Сборник коанов для эконометристов, жаждущих просветления.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Коан 6 Модели счетных данных | Розеттский камень" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Сборник коанов для эконометристов, жаждущих просветления." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Коан 6 Модели счетных данных | Розеттский камень" />
  
  <meta name="twitter:description" content="Сборник коанов для эконометристов, жаждущих просветления." />
  

<meta name="author" content="Пуассон, фея и два мексиканских негодяя">


<meta name="date" content="2019-03-15">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="ordchoice.html">
<link rel="next" href="disordered.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Напутственное слово</a></li>
<li class="chapter" data-level="2" data-path="installsoft.html"><a href="installsoft.html"><i class="fa fa-check"></i><b>2</b> Установка софта</a></li>
<li class="chapter" data-level="3" data-path="simplereg.html"><a href="simplereg.html"><i class="fa fa-check"></i><b>3</b> Коан о простой линейной регрессии</a></li>
<li class="chapter" data-level="4" data-path="binchoice.html"><a href="binchoice.html"><i class="fa fa-check"></i><b>4</b> Модели бинарного выбора</a></li>
<li class="chapter" data-level="5" data-path="ordchoice.html"><a href="ordchoice.html"><i class="fa fa-check"></i><b>5</b> Модели упорядоченного выбора</a></li>
<li class="chapter" data-level="6" data-path="poisreg.html"><a href="poisreg.html"><i class="fa fa-check"></i><b>6</b> Модели счетных данных</a></li>
<li class="chapter" data-level="7" data-path="disordered.html"><a href="disordered.html"><i class="fa fa-check"></i><b>7</b> Модели неупорядоченного выбора</a></li>
<li class="chapter" data-level="8" data-path="instruments.html"><a href="instruments.html"><i class="fa fa-check"></i><b>8</b> Интcтрументы для простой регрессии</a></li>
<li class="chapter" data-level="9" data-path="arma.html"><a href="arma.html"><i class="fa fa-check"></i><b>9</b> ARMA</a></li>
<li class="chapter" data-level="10" data-path="paneldata.html"><a href="paneldata.html"><i class="fa fa-check"></i><b>10</b> Панельные данные</a></li>
<li class="chapter" data-level="11" data-path="heterosked.html"><a href="heterosked.html"><i class="fa fa-check"></i><b>11</b> Гетероскедастичность в простой регрессии</a></li>
<li class="chapter" data-level="12" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>12</b> PCA</a></li>
<li class="chapter" data-level="13" data-path="dinpanel.html"><a href="dinpanel.html"><i class="fa fa-check"></i><b>13</b> Динамические панели</a></li>
<li class="chapter" data-level="14" data-path="tobit-heckit.html"><a href="tobit-heckit.html"><i class="fa fa-check"></i><b>14</b> TOBIT, HECKIT</a></li>
<li class="chapter" data-level="15" data-path="treatment.html"><a href="treatment.html"><i class="fa fa-check"></i><b>15</b> Treatment effect</a></li>
<li class="chapter" data-level="16" data-path="compatability.html"><a href="compatability.html"><i class="fa fa-check"></i><b>16</b> Что-то там про совместимость и языки</a></li>
<li class="chapter" data-level="17" data-path="dict.html"><a href="dict.html"><i class="fa fa-check"></i><b>17</b> Словарь</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Розеттский камень</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="poisreg" class="section level1">
<h1><span class="header-section-number">Коан 6</span> Модели счетных данных</h1>
<p>Загрузим необходимые пакеты.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse) <span class="co">#работа с данными и графики</span>
<span class="kw">library</span>(skimr) <span class="co">#красивое summary</span>
<span class="kw">library</span>(rio) <span class="co">#чтение .dta файлов</span>
<span class="kw">library</span>(vcd) <span class="co">#еще графики</span>
<span class="kw">library</span>(MASS) <span class="co">#отрицательное биномиальное</span>
<span class="kw">library</span>(lmtest) <span class="co">#для проверки гипотез</span>
<span class="kw">library</span>(pscl) <span class="co">#zero-inflation function</span>
<span class="kw">library</span>(margins) <span class="co">#для подсчета предельных эффектов</span></code></pre>
<p>Импортируем данные.</p>
<pre class="sourceCode r"><code class="sourceCode r">df =<span class="st"> </span><span class="kw">import</span>(<span class="dt">file =</span> <span class="st">&quot;fish.dta&quot;</span>)</code></pre>
<p>Данные содержат информацию о количестве рыбы, пойманной людьми на отдыхе.</p>
<p>Camper - наличие/отсутсвие палатки.
Child - количество детей, которых взяли на рыбалку.
Persons - количество людей в группе.
Count - количество пойманной рыбы</p>
<p>Посмотрим нам описательные статистики.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">skim_with</span>(<span class="dt">numeric =</span> <span class="kw">list</span>(<span class="dt">hist =</span> <span class="ot">NULL</span>, <span class="dt">p25 =</span> <span class="ot">NULL</span>, <span class="dt">p75 =</span> <span class="ot">NULL</span>))
<span class="kw">skim</span>(df)</code></pre>
<pre><code>Skim summary statistics
 n obs: 250 
 n variables: 4 

-- Variable type:numeric -----------------------------------------------------------------
 variable missing complete   n mean    sd p0 p50 p100
   camper       0      250 250 0.59  0.49  0   1    1
    child       0      250 250 0.68  0.85  0   0    3
    count       0      250 250 3.3  11.64  0   0  149
  persons       0      250 250 2.53  1.11  1   2    4</code></pre>
<p>Переменная <code>camper</code> принимает всего два значения, поэтому превратим ее в факторную переменную.</p>
<pre class="sourceCode r"><code class="sourceCode r">df =<span class="st"> </span><span class="kw">mutate</span>(df, <span class="dt">camper =</span> <span class="kw">factor</span>(camper))</code></pre>
<p>Наша задача - по имеющимся данным предсказать улов. Для начала посмотрим на распределение объясняемой переменной <code>count</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> count)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;count&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;frequency&#39;</span>, <span class="dt">title =</span> <span class="st">&#39;Distribution of count variable&#39;</span>)</code></pre>
<p><img src="05-poisreg_files/figure-html/hist-1.png" width="672" /></p>
<p>Предположим, что переменная имеет распределение Пуассона. Будем использовать пуассоновскую регрессию.
<span class="math display">\[
P(y=k)=exp(-\lambda) \lambda^k / k!
\]</span>
где <span class="math inline">\(\lambda=\exp(b_1 +b_2*x)\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">poisson =<span class="st"> </span><span class="kw">glm</span>(count <span class="op">~</span><span class="st"> </span>child <span class="op">+</span><span class="st"> </span>camper <span class="op">+</span><span class="st">  </span>persons, <span class="dt">family =</span> <span class="st">&quot;poisson&quot;</span>, <span class="dt">data =</span> df)
<span class="kw">summary</span>(poisson)</code></pre>
<pre><code>
Call:
glm(formula = count ~ child + camper + persons, family = &quot;poisson&quot;, 
    data = df)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-6.8096  -1.4431  -0.9060  -0.0406  16.1417  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.98183    0.15226  -13.02   &lt;2e-16 ***
child       -1.68996    0.08099  -20.87   &lt;2e-16 ***
camper1      0.93094    0.08909   10.45   &lt;2e-16 ***
persons      1.09126    0.03926   27.80   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 2958.4  on 249  degrees of freedom
Residual deviance: 1337.1  on 246  degrees of freedom
AIC: 1682.1

Number of Fisher Scoring iterations: 6</code></pre>
<p>Однако, заметим, что дисперсия и среднее значение объясняемой переменной не равны, как это предполагает распределение Пуассона.</p>
<pre class="sourceCode r"><code class="sourceCode r">df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(camper) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">var =</span> <span class="kw">var</span>(count), <span class="dt">mean =</span> <span class="kw">mean</span>(count))</code></pre>
<pre><code># A tibble: 2 x 3
  camper   var  mean
  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;
1 0       21.1  1.52
2 1      212.   4.54</code></pre>
<p>Оценим регрессию, предполагая отрицательное биномиальное распределение остатков. В этом случае, дисперсия распределения зависит от некоторого параметра и не равна среднему.</p>
<pre class="sourceCode r"><code class="sourceCode r">nb1 =<span class="st"> </span><span class="kw">glm.nb</span>(count <span class="op">~</span><span class="st"> </span>child <span class="op">+</span><span class="st"> </span>camper <span class="op">+</span><span class="st">  </span>persons, <span class="dt">data =</span> df)
<span class="kw">summary</span>(nb1)</code></pre>
<pre><code>
Call:
glm.nb(formula = count ~ child + camper + persons, data = df, 
    init.theta = 0.4635287626, link = log)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.6673  -0.9599  -0.6590  -0.0319   4.9433  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -1.6250     0.3304  -4.918 8.74e-07 ***
child        -1.7805     0.1850  -9.623  &lt; 2e-16 ***
camper1       0.6211     0.2348   2.645  0.00816 ** 
persons       1.0608     0.1144   9.273  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for Negative Binomial(0.4635) family taken to be 1)

    Null deviance: 394.25  on 249  degrees of freedom
Residual deviance: 210.65  on 246  degrees of freedom
AIC: 820.44

Number of Fisher Scoring iterations: 1

              Theta:  0.4635 
          Std. Err.:  0.0712 

 2 x log-likelihood:  -810.4440 </code></pre>
<p>Попробуем исключить из модели переменную <code>camper</code> и сравним качество двух моделей.</p>
<pre class="sourceCode r"><code class="sourceCode r">nb2 =<span class="st"> </span><span class="kw">update</span>(nb1, . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span>camper)
<span class="kw">waldtest</span>(nb1, nb2)</code></pre>
<pre><code>Wald test

Model 1: count ~ child + camper + persons
Model 2: count ~ child + persons
  Res.Df Df      F   Pr(&gt;F)   
1    246                      
2    247 -1 6.9979 0.008686 **
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Посчитаем предельный эффект в какой-нибудь точке.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">marginal_effects</span>(poisson, <span class="dt">variables =</span> <span class="st">&#39;camper&#39;</span>, <span class="dt">data =</span> df[<span class="dv">250</span>,])</code></pre>
<pre><code>  dydx_camper1
1     0.346628</code></pre>
<p>Тест отношения правдоподобия для вложенных моделей.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lrtest</span>(poisson, nb1)</code></pre>
<pre><code>Likelihood ratio test

Model 1: count ~ child + camper + persons
Model 2: count ~ child + camper + persons
  #Df  LogLik Df Chisq Pr(&gt;Chisq)    
1   4 -837.07                        
2   5 -405.22  1 863.7  &lt; 2.2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Можем посмотреть на результаты модели с “раздутыми нулями” (zero-inflated). Они предполагают большую частоту нулевых наблюдений.</p>
<pre class="sourceCode r"><code class="sourceCode r">zero_infl =<span class="st"> </span><span class="kw">zeroinfl</span>(count <span class="op">~</span><span class="st"> </span>. <span class="op">|</span><span class="st"> </span>., <span class="dt">data =</span> df, <span class="dt">dist =</span> <span class="st">&#39;negbin&#39;</span>)
<span class="kw">summary</span>(zero_infl)</code></pre>
<pre><code>
Call:
zeroinfl(formula = count ~ . | ., data = df, dist = &quot;negbin&quot;)

Pearson residuals:
     Min       1Q   Median       3Q      Max 
-0.71806 -0.56103 -0.38168  0.04398 16.16367 

Count model coefficients (negbin with log link):
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -1.6177     0.3202  -5.052 4.37e-07 ***
camper1       0.3856     0.2461   1.567 0.117128    
child        -1.2613     0.2473  -5.100 3.40e-07 ***
persons       1.0901     0.1117   9.761  &lt; 2e-16 ***
Log(theta)   -0.5929     0.1580  -3.753 0.000174 ***

Zero-inflation model coefficients (binomial with logit link):
            Estimate Std. Error z value Pr(&gt;|z|)
(Intercept) -11.9920    64.4408  -0.186    0.852
camper1     -10.7704    64.3725  -0.167    0.867
child        10.9517    64.3569   0.170    0.865
persons       0.2902     0.7314   0.397    0.692
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 

Theta = 0.5527 
Number of iterations in BFGS optimization: 68 
Log-likelihood: -395.5 on 9 Df</code></pre>
<div id="section-2" class="section level4">
<h4><span class="header-section-number">6.0.0.1</span> То же самое в стате</h4>
<p>Загружаем данные и смотрим описательные статистики.</p>
<pre class="stata"><code>use fish.dta
summarize</code></pre>
<pre><code>    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
      camper |       250        .588    .4931824          0          1
       child |       250        .684    .8503153          0          3
       count |       250       3.296    11.63503          0        149
     persons |       250       2.528     1.11273          1          4</code></pre>
<pre class="stata"><code>hist count</code></pre>
<pre><code>(bin=15, start=0, width=9.9333333)</code></pre>
<p>Строим Пуассоновскую регрессию.
В описательных статистиках:
<span class="math inline">\(AIC = -2log(L) + 2k\)</span>
<span class="math inline">\(AIC = -2log(L) + klog(N)\)</span></p>
<pre class="stata"><code>glm count camper child persons, family(poisson)</code></pre>
<pre><code>Iteration 0:   log likelihood = -965.92815  
Iteration 1:   log likelihood = -837.97093  
Iteration 2:   log likelihood = -837.07307  
Iteration 3:   log likelihood = -837.07248  
Iteration 4:   log likelihood = -837.07248  

Generalized linear models                          No. of obs      =       250
Optimization     : ML                              Residual df     =       246
                                                   Scale parameter =         1
Deviance         =  1337.079644                    (1/df) Deviance =  5.435283
Pearson          =  2910.627049                    (1/df) Pearson  =  11.83182

Variance function: V(u) = u                        [Poisson]
Link function    : g(u) = ln(u)                    [Log]

                                                   AIC             =   6.72858
Log likelihood   = -837.0724803                    BIC             = -21.19974

------------------------------------------------------------------------------
             |                 OIM
       count |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      camper |   .9309359   .0890869    10.45   0.000     .7563289    1.105543
       child |  -1.689957   .0809922   -20.87   0.000    -1.848699   -1.531215
     persons |   1.091262   .0392553    27.80   0.000     1.014323    1.168201
       _cons |  -1.981827    .152263   -13.02   0.000    -2.280257   -1.683397
------------------------------------------------------------------------------</code></pre>
<p>Можем посчитать AIC и BIC по другой формуле, аналогично выводу R.
<span class="math inline">\(AIC = \frac {-2log(L) + 2k}{N}\)</span></p>
<pre class="stata"><code>estat ic</code></pre>
<pre><code>Akaike&#39;s information criterion and Bayesian information criterion

-----------------------------------------------------------------------------
       Model |    Obs    ll(null)   ll(model)     df          AIC         BIC
-------------+---------------------------------------------------------------
           . |    250           .   -837.0725      4     1682.145    1696.231
-----------------------------------------------------------------------------
               Note:  N=Obs used in calculating BIC; see [R] BIC note</code></pre>
<p>Посмотрим, равны ли среднее значение и дисперсия, как это предполагает распределение Пуассона.</p>
<pre class="stata"><code>tabstat count, by(camper) stat(mean, variance) nototal</code></pre>
<pre><code>Summary for variables: count
     by categories of: camper (CAMPER)

  camper |      mean  variance
---------+--------------------
       0 |  1.524272  21.05578
       1 |  4.537415   212.401
------------------------------</code></pre>
<p>Предположим, что остатки имеют отрицательное биномиальное распределение.</p>
<pre class="stata"><code>nbreg count child camper persons</code></pre>
<pre><code>Fitting Poisson model:

Iteration 0:   log likelihood = -841.58831  
Iteration 1:   log likelihood = -837.07386  
Iteration 2:   log likelihood = -837.07248  
Iteration 3:   log likelihood = -837.07248  

Fitting constant-only model:

Iteration 0:   log likelihood = -582.76028  
Iteration 1:   log likelihood = -464.44518  
Iteration 2:   log likelihood = -464.43931  
Iteration 3:   log likelihood = -464.43931  

Fitting full model:

Iteration 0:   log likelihood = -438.02759  
Iteration 1:   log likelihood = -409.71171  
Iteration 2:   log likelihood = -405.34765  
Iteration 3:   log likelihood = -405.22204  
Iteration 4:   log likelihood =   -405.222  
Iteration 5:   log likelihood =   -405.222  

Negative binomial regression                      Number of obs   =        250
                                                  LR chi2(3)      =     118.43
Dispersion     = mean                             Prob &gt; chi2     =     0.0000
Log likelihood = -405.222                         Pseudo R2       =     0.1275

------------------------------------------------------------------------------
       count |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       child |   -1.78052   .1920379    -9.27   0.000    -2.156907   -1.404132
      camper |   .6211286   .2358072     2.63   0.008      .158955    1.083302
     persons |     1.0608   .1174733     9.03   0.000     .8305564    1.291043
       _cons |   -1.62499   .3294006    -4.93   0.000    -2.270603   -.9793765
-------------+----------------------------------------------------------------
    /lnalpha |   .7688868   .1538497                      .4673469    1.070427
-------------+----------------------------------------------------------------
       alpha |   2.157363   .3319098                      1.595755    2.916624
------------------------------------------------------------------------------
Likelihood-ratio test of alpha=0:  chibar2(01) =  863.70 Prob&gt;=chibar2 = 0.000</code></pre>
<p>Првоерим гипотезу о равенстве 0 коэффицинта при переменной <code>camper</code>. Проведем тест Вальда.</p>
<pre class="stata"><code>quietly: nbreg count child i.camper persons #скрыть вывод регрессии
test camper </code></pre>
<pre><code># invalid name
r(198);

end of do-file
r(198);</code></pre>
<p>Проведем lr-тест для вложенных моделей. Для него мы уже сохранили значения функций правдоподобия интересующих нас моделей.</p>
<pre class="stata"><code>estat ic</code></pre>
<pre><code># invalid name
r(19. estat ic

Akaike&#39;s information criterion and Bayesian information criterion

-----------------------------------------------------------------------------
       Model |    Obs    ll(null)   ll(model)     df          AIC         BIC
-------------+---------------------------------------------------------------
           . |    250   -464.4393    -405.222      5      820.444    838.0513
-----------------------------------------------------------------------------
               Note:  N=Obs used in calculating BIC; see [R] BIC note</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ordchoice.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="disordered.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Rosetta_Stone.pdf", "Rosetta_Stone.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
